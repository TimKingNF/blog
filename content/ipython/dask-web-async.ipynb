{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【译】异步计算：Web服务器+ Dask\n",
    "\n",
    "* Slug: Asynchronous Computation: Web Servers + Dask\n",
    "\n",
    "* Date: 2018-07-19\n",
    "\n",
    "* Category: python\n",
    "\n",
    "* Tags: dask, tornado, async, 翻译\n",
    "\n",
    "* Author: timking\n",
    "\n",
    "* Summary: 翻译，笔记"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 原文链接:  [Asynchronous Computation: Web Servers + Dask](https://gist.github.com/mrocklin/5e69b270d2a06aea7c288513709d921d)\n",
    "\n",
    "<img src=\"http://dask.pydata.org/en/latest/_images/dask_horizontal.svg\" align=\"right\"  width=\"30%\">\n",
    "让我们想象一个简单的Web服务器，它既可以快速加载页面，也可以在较慢的加载页面上执行一些计算。在我们的例子中，这将是一个简单的Fibonnaci服务应用程序，但您可以想象替换fib函数在一些输入数据上运行机器学习模型，从数据库中获取结果等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tornado.httpserver.HTTPServer at 0x11911e5f8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tornado.ioloop\n",
    "import tornado.web\n",
    "\n",
    "def fib(n):\n",
    "    if n < 2:\n",
    "        return n\n",
    "    else:\n",
    "        return fib(n - 1) + fib(n - 2)\n",
    "\n",
    "class FibHandler(tornado.web.RequestHandler):\n",
    "    def get(self, n):\n",
    "        result = fib(int(n))\n",
    "        self.write(str(result))\n",
    "        \n",
    "class FastHandler(tornado.web.RequestHandler):\n",
    "    def get(self):\n",
    "        self.write(\"Hello!\") \n",
    "        \n",
    "def make_app():\n",
    "    return tornado.web.Application([\n",
    "        (r\"/fast\", FastHandler),\n",
    "        (r\"/fib/(\\d+)\", FibHandler),\n",
    "    ])\n",
    "\n",
    "app = make_app()\n",
    "app.listen(8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 速度\n",
    "\n",
    "我们知道用户会将响应时间快速与否和网站权威内容和信任联系起来，因此我们希望衡量页面加载的速度。我们重点感兴趣的在于，在模拟我们的web服务器为许多用户提供服务时，在许多同时加载请求期间执行此操作的耗时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tornado.httpclient\n",
    "\n",
    "client = tornado.httpclient.AsyncHTTPClient()\n",
    "\n",
    "import tornado.gen\n",
    "from time import time\n",
    "\n",
    "@tornado.gen.coroutine\n",
    "def measure(url, n=100):\n",
    "    \"\"\" Get url n times concurrently.  Print duration. \"\"\"\n",
    "    start = time()\n",
    "    futures = [client.fetch(url) for i in range(n)]\n",
    "    results = yield futures\n",
    "    end = time()\n",
    "    print(url, ', %d simultaneous requests, ' %  n, 'total time: ', (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 耗时\n",
    "\n",
    "我们来看看以下几种执行情况的执行耗时\n",
    "\n",
    "* Tornado 一次执行 fast 返回耗时 10ms  \n",
    "*（实际上在我的机器上这个执行要更快）*\n",
    "\n",
    "\n",
    "* 执行100次 fast 大约在 100ms 左右, 所以这个是比较好的接近并发的效率  \n",
    "*（实际上，tornado在没有特殊处理的时候，仍然是一个串型执行的过程，原文给的例子中看不出来，但是从我的执行结果中可以很好的看出来，实际上并没有并发）*\n",
    "\n",
    "\n",
    "* 调用 fib 函数需要的时间\n",
    "\n",
    "\n",
    "* 调用 fib 100次需要大约100倍的时间，并没有那么多的并行性效率\n",
    "*（递归执行，这个差距更加明显）*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8000/fast , 1 simultaneous requests,  total time:  0.006060123443603516\n"
     ]
    }
   ],
   "source": [
    "tornado.ioloop.IOLoop.current().add_callback(measure, 'http://localhost:8000/fast', n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8000/fast , 100 simultaneous requests,  total time:  0.2758209705352783\n"
     ]
    }
   ],
   "source": [
    "tornado.ioloop.IOLoop.current().add_callback(measure, 'http://localhost:8000/fast', n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8000/fib/28 , 1 simultaneous requests,  total time:  0.16449999809265137\n"
     ]
    }
   ],
   "source": [
    "tornado.ioloop.IOLoop.current().add_callback(measure, 'http://localhost:8000/fib/28', n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8000/fib/28 , 100 simultaneous requests,  total time:  17.069420099258423\n"
     ]
    }
   ],
   "source": [
    "tornado.ioloop.IOLoop.current().add_callback(measure, 'http://localhost:8000/fib/28', n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 异步阻塞\n",
    "\n",
    "在下面的示例中，我们看到对路由fib/ 的一次缓慢调用会阻塞其他更快的请求："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8000/fast , 1 simultaneous requests,  total time:  5.0035529136657715\n",
      "http://localhost:8000/fib/35 , 1 simultaneous requests,  total time:  5.003870010375977\n"
     ]
    }
   ],
   "source": [
    "tornado.ioloop.IOLoop.current().add_callback(measure, 'http://localhost:8000/fib/35', n=1)\n",
    "tornado.ioloop.IOLoop.current().add_callback(measure, 'http://localhost:8000/fast', n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论\n",
    "\n",
    "这里存在两个问题:\n",
    "\n",
    "* 我们所有的fib调用都是独立的，我们希望与多个内核或附近的集群并行运行这些计算。\n",
    "\n",
    "* 我们缓慢的计算密集的fib函数的请求可能会妨碍我们的快速请求。一个慢用户可以影响其他所有人。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用dask 进行异步进程计算\n",
    "\n",
    "要解决这两个问题，我们将使用Dask将计算派发到其他进程或计算机中。因为Dask是一个异步框架，它可以很好地与Tornado或Asyncio集成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tornado.httpserver.HTTPServer at 0x1190f9550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "dask_client = Client(asynchronous=True)  # use local processes for now\n",
    "\n",
    "\n",
    "def fib(n):\n",
    "    if n < 2:\n",
    "        return n\n",
    "    else:\n",
    "        return fib(n - 1) + fib(n - 2)\n",
    "\n",
    "    \n",
    "class FibHandler(tornado.web.RequestHandler):\n",
    "    async def get(self, n):\n",
    "        future = dask_client.submit(fib, int(n))  # submit work to happen elsewhere\n",
    "        result = await future\n",
    "        self.write(str(result))\n",
    "\n",
    "        \n",
    "class MainHandler(tornado.web.RequestHandler):\n",
    "    async def get(self):\n",
    "        self.write(\"Hello, world\")\n",
    "\n",
    "        \n",
    "def make_app():\n",
    "    return tornado.web.Application([\n",
    "        (r\"/fast\", MainHandler),\n",
    "        (r\"/fib/(\\d+)\", FibHandler),\n",
    "                \n",
    "    ])\n",
    "\n",
    "app = make_app()\n",
    "app.listen(9000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 性能变化\n",
    "\n",
    "通过将 fib 派发到dask其他进程上，我们解决了两件事情\n",
    "\n",
    "### 并行计算\n",
    "\n",
    "我们现在支持在更少的时间处理更多的请求了。接下来的测验将会测验同时发起20个访问 fib(28) 的请求。在旧版本中，我们在几秒钟内按顺序计算这些（当浏览器完成时最后一个请求也会等待同样长的时间）。而在这个新版本中，许多都可以并行计算，所以这些请求都将会在几百毫秒内得到结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8000/fib/28 , 20 simultaneous requests,  total time:  3.5174269676208496\n"
     ]
    }
   ],
   "source": [
    "# Before parallelism\n",
    "tornado.ioloop.IOLoop.current().add_callback(measure, 'http://localhost:8000/fib/28', n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:9000/fib/28 , 20 simultaneous requests,  total time:  0.3605771064758301\n"
     ]
    }
   ],
   "source": [
    "# After parallelism\n",
    "tornado.ioloop.IOLoop.current().add_callback(measure, 'http://localhost:9000/fib/28', n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异步计算\n",
    "\n",
    "在之前当一个请求在忙于计算 fib(...) *陷入阻塞* 的时候 Tornado 同样也被阻塞了。此时 Tornado 它无法处理任何其他请求。当我们的服务提供这些昂贵、便宜的计算时，这将会成为严重的问题，开销少的请求会因为这种不必要的请求而挂起。\n",
    "\n",
    "由于Dask能够与Tornado或Asyncio等异步系统集成，因此我们的Web服务器可以在多个请求之间自由跳转，即使在后台进行计算时也是如此。在下面的例子中，我们看到即使首先开始慢速计算，快速计算也只需几毫秒就会返回。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8000/fast , 1 simultaneous requests,  total time:  4.998321056365967\n",
      "http://localhost:8000/fib/35 , 1 simultaneous requests,  total time:  5.000464916229248\n"
     ]
    }
   ],
   "source": [
    "# Before async\n",
    "tornado.ioloop.IOLoop.current().add_callback(measure, 'http://localhost:8000/fib/35', n=1)\n",
    "tornado.ioloop.IOLoop.current().add_callback(measure, 'http://localhost:8000/fast', n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:9000/fast , 1 simultaneous requests,  total time:  0.021255016326904297\n",
      "http://localhost:9000/fib/35 , 1 simultaneous requests,  total time:  5.034911870956421\n"
     ]
    }
   ],
   "source": [
    "# After async\n",
    "tornado.ioloop.IOLoop.current().add_callback(measure, 'http://localhost:9000/fib/35', n=1) \n",
    "tornado.ioloop.IOLoop.current().add_callback(measure, 'http://localhost:9000/fast', n=1) # 这个请求不会被阻塞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 其他注意点\n",
    "\n",
    "在这些情况下，今天人们倾向于使用 [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html) 或 [Celery](http://www.celeryproject.org/)。 \n",
    "\n",
    "* concurrent.futures 允许在一台机器上轻松实现并行性，并且可以很好地集成到异步框架中。 API正是我们上面展示的（Dask实现了concurrent.futures API）。但是，concurrent.futures不容易扩展到群集。\n",
    "\n",
    "\n",
    "* Celery更容易扩展到多台机器，但是具有更高的延迟，不能很好地缩小，并且需要一些努力来集成到异步框架中（或者至少这是我的理解，我的经验很浅） \n",
    "\n",
    "在这种情况下，Dask提供了两者的一些好处。它很容易在常见的单机情况下进行设置和使用，但也可以扩展到集群。它与异步框架很好地集成，只增加了非常小的延迟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roundtrip latency: 14.16 ms\n"
     ]
    }
   ],
   "source": [
    "async def f():\n",
    "    start = time()\n",
    "    result = await dask_client.submit(lambda x: x + 1, 10)\n",
    "    end = time()\n",
    "    print('Roundtrip latency: %.2f ms' % ((end - start) * 1000))\n",
    "    \n",
    "tornado.ioloop.IOLoop.current().add_callback(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
